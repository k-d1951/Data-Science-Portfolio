{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NPXUVVbYXcs2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import itertools\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import igraph\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "#nltk.download('punkt') # for tokenization\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68JngRE3Xcs7"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SqxVBXzDXcs9"
   },
   "outputs": [],
   "source": [
    "with open(\"testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    test = list(reader)\n",
    "test = [element[0].split(\" \") for element in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yNwHl7WPXctA"
   },
   "outputs": [],
   "source": [
    "with open(\"training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    train = list(reader)\n",
    "train = [element[0].split(\" \") for element in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r4zTIrDoXctC"
   },
   "outputs": [],
   "source": [
    "with open(\"node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qCn1nDlAXctF"
   },
   "outputs": [],
   "source": [
    "ID = [element[0] for element in node_info]\n",
    "year = [element[1] for element in node_info]\n",
    "title = [element[2] for element in node_info]\n",
    "authors = [element[3] for element in node_info]\n",
    "journal = [element[4] for element in node_info]\n",
    "abstract = [element[5] for element in node_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjps1AA5XctM"
   },
   "source": [
    "# Prepossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHVZ_EZrXctN"
   },
   "source": [
    "### Textual Preprossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yVTjs46NXctO"
   },
   "outputs": [],
   "source": [
    "# compute TFIDF vector for each title/authors/journal/abstract\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words=\"english\")\n",
    "TFIDF_title = vectorizer.fit_transform(title)\n",
    "TFIDF_author = vectorizer.fit_transform(authors)\n",
    "TFIDF_journal = vectorizer.fit_transform(journal)\n",
    "TFIDF_abstract = vectorizer.fit_transform(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ogp4hNYeXctQ"
   },
   "source": [
    "### Graph Preprossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y40kKTy0XctR"
   },
   "outputs": [],
   "source": [
    "                                       # -----Build graph ---- #\n",
    "\n",
    "# create raw empty directed graph\n",
    "g = igraph.Graph(directed=True)\n",
    "\n",
    "# add vertices\n",
    "nodes = ID\n",
    "g.add_vertices(nodes)\n",
    "\n",
    "# add edges\n",
    "edges = [(element[0], element[1]) for element in train if element[2] == \"1\"]\n",
    "g.add_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "A3r9zldAXctT"
   },
   "outputs": [],
   "source": [
    "                           # ----- Generate features in the graph ---- #\n",
    "\n",
    "# The adjacency list representation is a list of lists. \n",
    "# Each item of the outer list belongs to a single vertex of the graph. \n",
    "# The inner list contains the neighbors of the given vertex.\n",
    "adjlist = [set(x) for x in g.get_adjlist(mode=\"ALL\")]\n",
    "\n",
    "# degree\n",
    "degrees = g.degree()\n",
    "\n",
    "# page rank\n",
    "page_rank = g.pagerank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEMIfZf2XctW"
   },
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_BSqnaLXctW"
   },
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M7QZygVjXctX"
   },
   "outputs": [],
   "source": [
    "                                        # ---- Textual Features ---- #\n",
    "overlapping_words_in_title = [] # number of overlapping words in title\n",
    "temp_distance = [] # temporal distance between the papers\n",
    "common_authors = [] # number of common authors\n",
    "common_words_in_journal = [] # number of common words in journal\n",
    "overlapping_words_in_abstract = []  # number of overlapping words in abstract\n",
    "sim_title = []  # cosine similarity of title\n",
    "sim_author = []  # cosine similarity of authors\n",
    "sim_journal = []  # cosine similarity of journal\n",
    "sim_abstract = [] # consine similarity of abstract\n",
    "\n",
    "                                        # ---- Graphical Features ---- #\n",
    "common_neighbors = [] # common neighbors\n",
    "pref_attach = [] # preferential attachment\n",
    "jaccard_sim = [] # Jaccard similarity coefficient\n",
    "adam_adar_sim = [] # Adamic Adar similarity\n",
    "page_rank_source = [] # page rank\n",
    "page_rank_target = [] # page rank\n",
    "#shortest_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P3HZV7oPXcta"
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(source, target, graph):\n",
    "    s_neighbors = set(graph.neighbors(source))\n",
    "    t_neighbors = set(graph.neighbors(target))\n",
    "    intersect = len(s_neighbors.intersection(t_neighbors))\n",
    "    union = len(s_neighbors.union(t_neighbors))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(intersect / float(union))\n",
    "\n",
    "        #-----------------#\n",
    "    \n",
    "def adam_adar_similarity(source, target, graph):\n",
    "    s_neighbors = set(graph.neighbors(source))\n",
    "    t_neighbors = set(graph.neighbors(target))\n",
    "    sim = 0.0\n",
    "    for i in s_neighbors.intersection(t_neighbors):\n",
    "        if math.log(len(graph.neighbors(i))) == 0:\n",
    "            sim += 0.0\n",
    "        else:\n",
    "            sim += float(1 / math.log(len(graph.neighbors(i))))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "crqp_LJTXctd"
   },
   "outputs": [],
   "source": [
    "# create features for train set\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "count = 0.0\n",
    "\n",
    "for i in range(len(train)):\n",
    "    source = train[i][0]\n",
    "    target = train[i][1]\n",
    "    index_source = ID.index(source)\n",
    "    index_target = ID.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0] == source][0]\n",
    "    target_info = [element for element in node_info if element[0] == target][0]\n",
    "    \n",
    "    # prepossing title\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    # prepossing author\n",
    "    source_author = source_info[3].split(\",\")\n",
    "    target_author = target_info[3].split(\",\")\n",
    "    \n",
    "    # prepossing abstract\n",
    "    source_abstract = source_info[5].lower().split(\" \")  \n",
    "    source_abstract = [token for token in source_abstract if token not in stpwds] \n",
    "    source_abstract = [stemmer.stem(token) for token in source_abstract]  \n",
    "\n",
    "    target_abstract = target_info[5].lower().split(\" \") \n",
    "    target_abstract = [token for token in target_abstract if token not in stpwds]  \n",
    "    target_abstract = [stemmer.stem(token) for token in target_abstract]\n",
    "    \n",
    "    # Generate textual features\n",
    "    # 1\n",
    "    overlapping_words_in_title.append(len(set(source_title).intersection(set(target_title))))\n",
    "    # 2\n",
    "    temp_distance.append(int(source_info[1]) - int(target_info[1]))\n",
    "    # 3\n",
    "    common_authors.append(len(set(source_author).intersection(set(target_author))))\n",
    "    # 4\n",
    "    common_words_in_journal.append(len(set(source_info[4]).intersection(set(target_info[4]))))\n",
    "    # 5\n",
    "    overlapping_words_in_abstract.append(len(set(source_abstract).intersection(set(target_abstract))))\n",
    "    # 6\n",
    "    sim_title.append(cosine_similarity(TFIDF_title[index_source], TFIDF_title[index_target]))\n",
    "    # 7\n",
    "    sim_author.append(cosine_similarity(TFIDF_author[index_source], TFIDF_author[index_target]))\n",
    "    # 8\n",
    "    sim_journal.append(cosine_similarity(TFIDF_journal[index_source], TFIDF_journal[index_target]))\n",
    "    # 9\n",
    "    sim_abstract.append(cosine_similarity(TFIDF_abstract[index_source], TFIDF_abstract[index_target]))\n",
    "\n",
    "    # generate graphical features\n",
    "    # 10\n",
    "    common_neighbors.append(len(adjlist[index_source].intersection(adjlist[index_target])))\n",
    "    # 11\n",
    "    pref_attach.append(int(degrees[index_source] * degrees[index_target]))\n",
    "    # 12\n",
    "    jaccard_sim.append(jaccard_similarity(index_source, index_target, g))\n",
    "    # 13\n",
    "    adam_adar_sim.append(adam_adar_similarity(index_source, index_target, g))\n",
    "    # 14\n",
    "    page_rank_source.append(page_rank[index_target])\n",
    "    # 15\n",
    "    page_rank_target.append(page_rank[index_source])\n",
    "    # 16\n",
    "    #shortest_paths_t.append(len(g.shortest_paths_dijkstra(source=index_source, target=index_target, weights=None, mode=1)))\n",
    "    \n",
    "    count += 1\n",
    "    if count % 5000 == True:\n",
    "        print(count,'training examples processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RSNJvVSkXctg"
   },
   "outputs": [],
   "source": [
    "# merge all the features and save\n",
    "train_features = np.array(\n",
    "    [overlapping_words_in_title, temp_distance, common_authors, common_words_in_journal, \n",
    "     overlapping_words_in_abstract, sim_title, sim_author, sim_journal, sim_abstract, \n",
    "     common_neighbors, pref_attach, jaccard_sim, adam_adar_sim, page_rank_source, \n",
    "     page_rank_target]).astype(np.float64).T\n",
    "\n",
    "\n",
    "# save\n",
    "np.savetxt('train_features.txt', train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8myoohHXctj"
   },
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yvOPRFpVXctk"
   },
   "outputs": [],
   "source": [
    "# create features for test set\n",
    "                                        # ---- Textual Features ---- #\n",
    "overlapping_words_in_title_t = [] # number of overlapping words in title\n",
    "temp_distance_t = [] # temporal distance between the papers\n",
    "common_authors_t = [] # number of common authors\n",
    "common_words_in_journal_t = [] # number of common words in journal\n",
    "overlapping_words_in_abstract_t = []  # number of overlapping words in abstract\n",
    "sim_title_t = []  # cosine similarity of title\n",
    "sim_author_t = []  # cosine similarity of authors\n",
    "sim_journal_t = []  # cosine similarity of journal\n",
    "sim_abstract_t = [] # consine similarity of abstract\n",
    "\n",
    "                                        # ---- Graphical Features ---- #\n",
    "common_neighbors_t = [] # common neighbors\n",
    "pref_attach_t = [] # preferential attachment\n",
    "jaccard_sim_t = [] # Jaccard similarity coefficient\n",
    "adam_adar_sim_t = [] # Adamic Adar similarity\n",
    "page_rank_source_t = [] # page rank\n",
    "page_rank_target_t = [] # page rank\n",
    "#shortest_paths_t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "rExB_QZwXctn",
    "outputId": "71e2078e-fac2-49ee-a352-16b52283066c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processed\n",
      "5001 training examples processed\n",
      "10001 training examples processed\n",
      "15001 training examples processed\n",
      "20001 training examples processed\n",
      "25001 training examples processed\n",
      "30001 training examples processed\n"
     ]
    }
   ],
   "source": [
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "count = 0\n",
    "for i in range(len(test)):\n",
    "    source = test[i][0]\n",
    "    target = test[i][1]\n",
    "    index_source = ID.index(source)\n",
    "    index_target = ID.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0] == source][0]\n",
    "    target_info = [element for element in node_info if element[0] == target][0]\n",
    "    \n",
    "    # prepossing title\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "    \n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "    \n",
    "    # prepossing author\n",
    "    source_author = source_info[3].split(\",\")\n",
    "    target_author = target_info[3].split(\",\")\n",
    "    \n",
    "    # prepossing abstract\n",
    "    source_abstract = source_info[5].lower().split(\" \")  \n",
    "    source_abstract = [token for token in source_abstract if token not in stpwds] \n",
    "    source_abstract = [stemmer.stem(token) for token in source_abstract]  \n",
    "\n",
    "    target_abstract = target_info[5].lower().split(\" \") \n",
    "    target_abstract = [token for token in target_abstract if token not in stpwds]  \n",
    "    target_abstract = [stemmer.stem(token) for token in target_abstract]\n",
    "    \n",
    "    # Generate textual features\n",
    "    # 1\n",
    "    overlapping_words_in_title_t.append(len(set(source_title).intersection(set(target_title))))\n",
    "    # 2\n",
    "    temp_distance_t.append(int(source_info[1]) - int(target_info[1]))\n",
    "    # 3\n",
    "    common_authors_t.append(len(set(source_author).intersection(set(target_author))))\n",
    "    # 4\n",
    "    common_words_in_journal_t.append(len(set(source_info[4]).intersection(set(target_info[4]))))\n",
    "    # 5\n",
    "    overlapping_words_in_abstract_t.append(len(set(source_abstract).intersection(set(target_abstract))))\n",
    "    # 6\n",
    "    sim_title_t.append(cosine_similarity(TFIDF_title[index_source], TFIDF_title[index_target]))\n",
    "    # 7\n",
    "    sim_author_t.append(cosine_similarity(TFIDF_author[index_source], TFIDF_author[index_target]))\n",
    "    # 8\n",
    "    sim_journal_t.append(cosine_similarity(TFIDF_journal[index_source], TFIDF_journal[index_target]))\n",
    "    # 9\n",
    "    sim_abstract_t.append(cosine_similarity(TFIDF_abstract[index_source], TFIDF_abstract[index_target]))\n",
    "\n",
    "    # generate graphical features\n",
    "    # 10\n",
    "    common_neighbors_t.append(len(adjlist[index_source].intersection(adjlist[index_target])))\n",
    "    # 11\n",
    "    pref_attach_t.append(int(degrees[index_source] * degrees[index_target]))\n",
    "    # 12\n",
    "    jaccard_sim_t.append(jaccard_similarity(index_source, index_target, g))\n",
    "    # 13\n",
    "    adam_adar_sim_t.append(adam_adar_similarity(index_source, index_target, g))\n",
    "    # 14\n",
    "    page_rank_source_t.append(page_rank[index_target])\n",
    "    # 15\n",
    "    page_rank_target_t.append(page_rank[index_source])\n",
    "    #\n",
    "    #shortest_paths_t.append(len(g.shortest_paths_dijkstra(source=index_source, target=index_target, weights=None, mode=1)))\n",
    "    \n",
    "    count += 1\n",
    "    if count % 5000 == True:\n",
    "        print(count,'testing examples processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rd9kaH44Xctr"
   },
   "outputs": [],
   "source": [
    "# merge all the features and save\n",
    "test_features = np.array(\n",
    "    [overlapping_words_in_title_t, temp_distance_t, common_authors_t, common_words_in_journal_t, \n",
    "     overlapping_words_in_abstract_t, sim_title_t, sim_author_t, sim_journal_t, sim_abstract_t, \n",
    "     common_neighbors_t, pref_attach_t, jaccard_sim_t, adam_adar_sim_t, page_rank_source_t, \n",
    "     page_rank_target_t]).astype(np.float64).T\n",
    "\n",
    "# save\n",
    "np.savetxt('test_features.txt', test_features)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Create_Features.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
